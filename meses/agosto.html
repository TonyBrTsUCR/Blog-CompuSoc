<!DOCTYPE html>
<html lang="es">
  <head>
    <meta charset="UTF-8" />
    <title>Agosto 2025</title>
    <link rel="stylesheet" href="../Blog-CompuSoc/css/style.css" />
    <link
      href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;600&display=swap"
      rel="stylesheet"
    />
  </head>

  <body>
    <header class="hero-header">
      <div class="overlay"></div>
      <div class="hero-text">
        <h1>Agosto 2025</h1>
        <p>AI and Trust</p>
      </div>
    </header>

    <section class="month-card">
      <h2>Noticia seleccionada</h2>

      <div class="color-line line-primary"></div>

      <p><strong>Título:</strong> AI and Trust</p>
      <p><strong>Fuente:</strong> Communications of the ACM</p>
      <p><strong>Fecha:</strong> Agosto 2025</p>
      <p>
        <strong>Enlace:</strong>
        <a
          href="https://dx.doi.org/10.1145/3737610"
          target="_blank"
          class="news-link"
        >
          Ver noticia
        </a>
      </p>

      <div class="section-title">Resumen</div>

      <div class="color-line line-secondary"></div>

      <p>
        El artículo explica que la confianza en la inteligencia artificial no debe basarse en percepciones emocionales, sino en mecanismos verificables que permitan asegurar su funcionamiento. Schneier distingue entre la confianza interpersonal, propia de relaciones humanas, y la confianza social, que depende de leyes, auditorías y sistemas diseñados para garantizar comportamientos predecibles. Señala que la interacción mediante lenguaje natural puede llevar a que las personas perciban a la IA como si fuera un aliado, cuando en realidad es un servicio controlado por entidades con intereses propios. También expone que estos sistemas pueden ser vulnerables a manipulación de datos, ataques y usos poco transparentes. Por ello, destaca que la estabilidad y la confianza pública en la tecnología dependen de regulaciones que definan cómo deben operar estos modelos, qué valores siguen y qué responsabilidades recaen sobre quienes los desarrollan.
      </p>

      <div class="section-title">Análisis</div>

      <div class="color-line line-primary"></div>

      <div class="analysis-subtitle">Impacto global</div>
      <p>
        El texto muestra que la expansión de la inteligencia artificial está superando la capacidad de las sociedades para generar normas claras sobre su uso. Este desbalance genera riesgos en sectores como salud, finanzas, justicia y educación, donde las decisiones automatizadas pueden afectar directamente la vida de las personas. Schneier resalta que uno de los mayores desafíos es la integridad, es decir, la posibilidad de que un sistema sea alterado sin que los usuarios lo detecten. A nivel internacional, esto impulsa la necesidad de mecanismos de auditoría, certificación, transparencia y supervisión que permitan confiar en que las decisiones generadas por la IA no estén manipuladas ni respondan a intereses ocultos. La noticia evidencia que la regulación es una pieza clave para garantizar que la tecnología se utilice de manera ética y segura.
      </p>

      <div class="analysis-subtitle">Impacto en Costa Rica</div>
      <p>
        En Costa Rica, donde los servicios digitales se están expandiendo rápidamente, la ausencia de normas específicas sobre el uso de inteligencia artificial crea vulnerabilidades en ámbitos como banca digital, educación virtual, servicios médicos y gestión de datos personales. Esto hace necesario adoptar principios que aseguren transparencia algorítmica, auditorías técnicas y protección reforzada de la información. Un enfoque regulatorio alineado con estándares internacionales permitiría fortalecer la confianza ciudadana y reducir riesgos asociados a decisiones automatizadas. Además, ayudaría a prevenir errores, sesgos o fallos que puedan afectar derechos fundamentales en el proceso de digitalización del país.
      </p>

      <div class="month-nav">
        <a href="../index.html" class="month-button">← Volver al inicio</a>
        <a href="setiembre.html" class="month-button">Siguiente mes →</a>
      </div>
    </section>

    <footer class="footer">
      <p>© 2025 – Sitio creado por Anthony Barrantes Alfaro</p>
    </footer>
  </body>
</html>
